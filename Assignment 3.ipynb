{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f86c36bd",
   "metadata": {},
   "source": [
    "## Problem 3 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "9fea0413",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import train_test_split\n",
    "import re\n",
    "import math\n",
    "\n",
    "dataset = pd.read_csv('train.csv')\n",
    "\n",
    "\n",
    "# Feature that tells whether a passenger had a cabin on the Titanic\n",
    "dataset['Has_Cabin'] = dataset[\"Cabin\"].apply(lambda x: 0 if type(x) == float else 1)\n",
    "\n",
    "# Create new feature FamilySize as a combination of SibSp and Parch\n",
    "dataset['FamilySize'] = dataset['SibSp'] + dataset['Parch'] + 1\n",
    "\n",
    "# Create new feature IsAlone from FamilySize\n",
    "dataset['IsAlone'] = 0\n",
    "dataset.loc[dataset['FamilySize'] == 1, 'IsAlone'] = 1\n",
    "\n",
    "# Remove all NULLS in the Embarked column\n",
    "dataset['Embarked'] = dataset['Embarked'].fillna('S')\n",
    "\n",
    "# Remove all NULLS in the Fare column\n",
    "dataset['Fare'] = dataset['Fare'].fillna(dataset['Fare'].median())\n",
    "\n",
    "# Remove all NULLS in the Age column\n",
    "age_avg = dataset['Age'].mean()\n",
    "age_std = dataset['Age'].std()\n",
    "age_null_count = dataset['Age'].isnull().sum()\n",
    "age_null_random_list = np.random.randint(age_avg - age_std, age_avg + age_std, size=age_null_count)\n",
    "# Next line has been improved to avoid warning\n",
    "dataset.loc[np.isnan(dataset['Age']), 'Age'] = age_null_random_list\n",
    "dataset['Age'] = dataset['Age'].astype(int)\n",
    "    \n",
    "# Define function to extract titles from passenger names\n",
    "def get_title(name):\n",
    "    title_search = re.search(' ([A-Za-z]+)\\.', name)\n",
    "    # If the title exists, extract and return it.\n",
    "    if title_search:\n",
    "        return title_search.group(1)\n",
    "    return \"\"\n",
    "\n",
    "dataset['Title'] = dataset['Name'].apply(get_title)\n",
    "\n",
    "# Group all non-common titles into one single grouping \"Rare\"\n",
    "dataset['Title'] = dataset['Title'].replace(['Lady', 'Countess','Capt', 'Col','Don', 'Dr', 'Major', 'Rev', 'Sir', 'Jonkheer', 'Dona'], 'Rare')\n",
    "\n",
    "dataset['Title'] = dataset['Title'].replace('Mlle', 'Miss')\n",
    "dataset['Title'] = dataset['Title'].replace('Ms', 'Miss')\n",
    "dataset['Title'] = dataset['Title'].replace('Mme', 'Mrs')\n",
    "    \n",
    "\n",
    "# Mapping Sex\n",
    "dataset['Sex'] = dataset['Sex'].map( {'female': 0, 'male': 1} ).astype(int)\n",
    "\n",
    "# Mapping titles\n",
    "title_mapping = {\"Mr\": 1, \"Master\": 2, \"Mrs\": 3, \"Miss\": 4, \"Rare\": 5}\n",
    "dataset['Title'] = dataset['Title'].map(title_mapping)\n",
    "dataset['Title'] = dataset['Title'].fillna(0)\n",
    "\n",
    "# Mapping Embarked\n",
    "dataset['Embarked'] = dataset['Embarked'].map( {'S': 0, 'C': 1, 'Q': 2} ).astype(int)\n",
    "\n",
    "# Mapping Fare\n",
    "dataset.loc[ dataset['Fare'] <= 7.91, 'Fare'] = 0\n",
    "dataset.loc[(dataset['Fare'] > 7.91) & (dataset['Fare'] <= 14.454), 'Fare'] = 1\n",
    "dataset.loc[(dataset['Fare'] > 14.454) & (dataset['Fare'] <= 31), 'Fare']   = 2\n",
    "dataset.loc[ dataset['Fare'] > 31, 'Fare'] \t\t\t\t\t\t\t        = 3\n",
    "dataset['Fare'] = dataset['Fare'].astype(int)\n",
    "\n",
    "# Mapping Age\n",
    "dataset.loc[ dataset['Age'] <= 16, 'Age'] \t\t\t\t\t       = 0\n",
    "dataset.loc[(dataset['Age'] > 16) & (dataset['Age'] <= 32), 'Age'] = 1\n",
    "dataset.loc[(dataset['Age'] > 32) & (dataset['Age'] <= 48), 'Age'] = 2\n",
    "dataset.loc[(dataset['Age'] > 48) & (dataset['Age'] <= 64), 'Age'] = 3\n",
    "dataset.loc[ dataset['Age'] > 64, 'Age'] ;\n",
    "    \n",
    "drop_elements = ['PassengerId', 'Name', 'Ticket', 'Cabin', 'SibSp']\n",
    "dataset = dataset.drop(drop_elements, axis = 1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e618afc5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "891\n",
      "342\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Embarked</th>\n",
       "      <th>Has_Cabin</th>\n",
       "      <th>FamilySize</th>\n",
       "      <th>IsAlone</th>\n",
       "      <th>Title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Survived  Pclass  Sex  Age  Parch  Fare  Embarked  Has_Cabin  FamilySize  \\\n",
       "0         0       3    1    1      0     0         0          0           2   \n",
       "1         1       1    0    2      0     3         1          1           2   \n",
       "2         1       3    0    1      0     1         0          0           1   \n",
       "\n",
       "   IsAlone  Title  \n",
       "0        0      1  \n",
       "1        0      3  \n",
       "2        1      4  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(len(dataset))\n",
    "print(len(dataset.loc[dataset[\"Survived\"]==1]))\n",
    "dataset.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cc135fbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define function to calculate Gini Impurity\n",
    "def get_gini_impurity(survived_count, total_count):\n",
    "    survival_prob = survived_count/total_count\n",
    "    not_survival_prob = (1 - survival_prob)\n",
    "    random_observation_survived_prob = survival_prob\n",
    "    random_observation_not_survived_prob = (1 - random_observation_survived_prob)\n",
    "    mislabelling_survided_prob = not_survival_prob * random_observation_survived_prob\n",
    "    mislabelling_not_survided_prob = survival_prob * random_observation_not_survived_prob\n",
    "    gini_impurity = mislabelling_survided_prob + mislabelling_not_survided_prob\n",
    "    return gini_impurity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f68adabe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_entropy(column):\n",
    "    counts = np.bincount(column)\n",
    "    probs = counts / len(column)\n",
    "    entropy = 0\n",
    "    for prob in probs:\n",
    "        if prob>0:\n",
    "            entropy += prob * math.log(prob,2)\n",
    "    return -entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e2ee8e5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gini Starting Node: 0.47301295786144265\n",
      "Info gain starting node: 0.9607079018756469\n",
      "\n",
      "Gini Men Node: 0.3064437162277843\n",
      "Gini Women Node: 0.3828350034484158\n",
      "Gini Sex Decrease: -0.13964795747285214\n",
      "Info gain sex node: 0.9362046432498521\n",
      "Info gain sex dcrease: -0.024503258625794833\n",
      "\n",
      "Gini Title 1 Node: 0.26425329886377663\n",
      "Gini Title Others Node: 0.42170207898424317\n",
      "Gini Title Decrease: -0.14267004758907514\n",
      "Info gain title node: 1.6627939980717152\n",
      "Info gain title decrease: 0.7020860961960683\n"
     ]
    }
   ],
   "source": [
    "#Gini and info gain of starting node\n",
    "gini_starting = get_gini_impurity(342,891)\n",
    "print(\"Gini Starting Node:\",gini_starting)\n",
    "\n",
    "info_starting = calc_entropy(dataset[\"Survived\"])\n",
    "print(\"Info gain starting node:\",info_starting)\n",
    "print()\n",
    "#gini and info gain of sex\n",
    "gini_men = get_gini_impurity(109, 577)\n",
    "print(\"Gini Men Node:\",gini_men)\n",
    "gini_women = get_gini_impurity(233,314)\n",
    "print(\"Gini Women Node:\",gini_women)\n",
    "\n",
    "men_weight = 577/891\n",
    "women_weight = 314/891\n",
    "weighted_gini_sex_split = (gini_men * men_weight) + (gini_women * women_weight)\n",
    "\n",
    "sex_gini_decrease = weighted_gini_sex_split - gini_starting\n",
    "print(\"Gini Sex Decrease:\",sex_gini_decrease)\n",
    "\n",
    "info_sex = calc_entropy(dataset[\"Sex\"])\n",
    "print(\"Info gain sex node:\",info_sex)\n",
    "\n",
    "info_sex_decrease = info_sex-info_starting\n",
    "print(\"Info gain sex dcrease:\", info_sex_decrease)\n",
    "print()\n",
    "\n",
    "#gini and info gain by title\n",
    "gini_title_1 = get_gini_impurity(81,517)\n",
    "print(\"Gini Title 1 Node:\",gini_title_1)\n",
    "gini_title_others = get_gini_impurity(261,374)\n",
    "print(\"Gini Title Others Node:\",gini_title_others)\n",
    "\n",
    "title_1_weight = 517/891\n",
    "title_others_weight = 374/891\n",
    "weighted_gini_title_split = (gini_title_1 * title_1_weight) + (gini_title_others * title_others_weight)\n",
    "\n",
    "title_gini_decrease = weighted_gini_title_split - gini_starting\n",
    "print(\"Gini Title Decrease:\",title_gini_decrease)\n",
    "\n",
    "\n",
    "info_title_1 = calc_entropy(dataset[\"Title\"])\n",
    "print(\"Info gain title node:\",info_title_1)\n",
    "\n",
    "info_title_decrease = info_title_1-info_starting\n",
    "print(\"Info gain title decrease:\",info_title_decrease)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "af4fc7dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Node:\n",
    "    def __init__(self, predicted_class):\n",
    "        self.predicted_class = predicted_class\n",
    "        self.feature_index = 0\n",
    "        self.threshold = 0\n",
    "        self.left = None\n",
    "        self.right = None\n",
    "\n",
    "class MyDecisionTreeClassifier:\n",
    "    def __init__(self, max_depth=None):\n",
    "        self.max_depth = max_depth\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        self.n_classes_ = len(set(y))\n",
    "        self.n_features_ = X.shape[1]\n",
    "        self.tree_ = self._grow_tree(X, y)\n",
    "\n",
    "    def predict(self, X):\n",
    "        return [self._predict(inputs) for inputs in X]\n",
    "\n",
    "    def _best_split(self, X, y):\n",
    "        m = y.size\n",
    "        if m <= 1:\n",
    "            return None, None\n",
    "        num_parent = [np.sum(y == c) for c in range(self.n_classes_)]\n",
    "        best_gini = 1.0 - sum((n / m) ** 2 for n in num_parent)\n",
    "        best_idx, best_thr = None, None\n",
    "        for idx in range(self.n_features_):\n",
    "            thresholds, classes = zip(*sorted(zip(X[:, idx], y)))\n",
    "            num_left = [0] * self.n_classes_\n",
    "            num_right = num_parent.copy()\n",
    "            for i in range(1, m):\n",
    "                c = classes[i - 1]\n",
    "                num_left[c] += 1\n",
    "                num_right[c] -= 1\n",
    "                gini_left = 1.0 - sum(\n",
    "                    (num_left[x] / i) ** 2 for x in range(self.n_classes_)\n",
    "                )\n",
    "                gini_right = 1.0 - sum(\n",
    "                    (num_right[x] / (m - i)) ** 2 for x in range(self.n_classes_)\n",
    "                )\n",
    "                gini = (i * gini_left + (m - i) * gini_right) / m\n",
    "                if thresholds[i] == thresholds[i - 1]:\n",
    "                    continue\n",
    "                if gini < best_gini:\n",
    "                    best_gini = gini\n",
    "                    best_idx = idx\n",
    "                    best_thr = (thresholds[i] + thresholds[i - 1]) / 2\n",
    "        return best_idx, best_thr\n",
    "\n",
    "    def _grow_tree(self, X, y, depth=0):\n",
    "        num_samples_per_class = [np.sum(y == i) for i in range(self.n_classes_)]\n",
    "        predicted_class = np.argmax(num_samples_per_class)\n",
    "        node = Node(predicted_class=predicted_class)\n",
    "        if depth < self.max_depth:\n",
    "            idx, thr = self._best_split(X, y)\n",
    "            if idx is not None:\n",
    "                indices_left = X[:, idx] < thr\n",
    "                X_left, y_left = X[indices_left], y[indices_left]\n",
    "                X_right, y_right = X[~indices_left], y[~indices_left]\n",
    "                node.feature_index = idx\n",
    "                node.threshold = thr\n",
    "                node.left = self._grow_tree(X_left, y_left, depth + 1)\n",
    "                node.right = self._grow_tree(X_right, y_right, depth + 1)\n",
    "        return node\n",
    "\n",
    "    def _predict(self, inputs):\n",
    "        node = self.tree_\n",
    "        while node.left:\n",
    "            if inputs[node.feature_index] < node.threshold:\n",
    "                node = node.left\n",
    "            else:\n",
    "                node = node.right\n",
    "        return node.predicted_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "25be2cda",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Max Depth  Average Accuracy\n",
      "         1          0.782285\n",
      "         2          0.799189\n",
      "         3          0.828277\n",
      "         4          0.819288\n",
      "         5          0.823795\n",
      "         6          0.804782\n",
      "         7          0.802472\n",
      "         8          0.804782\n",
      "         9          0.811523\n",
      "        10          0.807041\n",
      "        11          0.801436\n"
     ]
    }
   ],
   "source": [
    "cv = KFold(n_splits=10)\n",
    "accuracies = []\n",
    "max_attributes=len(list(dataset))\n",
    "depth_range= range(1, max_attributes+1)\n",
    "\n",
    "for depth in depth_range:\n",
    "    fold_accuracy = []\n",
    "    tree_model = MyDecisionTreeClassifier(max_depth=depth)\n",
    "    for train_fold, valid_fold in cv.split(dataset):\n",
    "        f_train = dataset.loc[train_fold]\n",
    "        f_valid = dataset.loc[valid_fold]\n",
    "        \n",
    "        model = tree_model.fit(X=f_train.drop([\"Survived\"],axis=1),y=f_train[\"Survived\"])\n",
    "        y_pred = tree_model.predict(f_valid.drop([\"Survived\"],axis=1))\n",
    "        valid_acc = accuracy_score(f_valid[\"Survived\"], y_pred)\n",
    "        fold_accuracy.append(valid_acc)\n",
    "        \n",
    "    avg = sum(fold_accuracy)/len(fold_accuracy)\n",
    "    accuracies.append(avg)\n",
    "\n",
    "df = pd.DataFrame({\"Max Depth\": depth_range, \"Average Accuracy\": accuracies})\n",
    "df=df[[\"Max Depth\", \"Average Accuracy\"]]\n",
    "print(df.to_string(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "51c1a5c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8169491525423729\n"
     ]
    }
   ],
   "source": [
    "X=dataset.drop(['Survived'], axis=1).values\n",
    "y=dataset['Survived']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)\n",
    "\n",
    "decision_tree = MyDecisionTreeClassifier(max_depth=3)\n",
    "decision_tree.fit(X_train, y_train)\n",
    "\n",
    "y_pred = decision_tree.predict(X_test)\n",
    "acc_decision_tree = accuracy_score(y_pred,y_test)\n",
    "print(acc_decision_tree)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8df2dc8c",
   "metadata": {},
   "source": [
    "## Problem 4 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "14b95365",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8305084745762712\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "class AdaBoost:\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.stumps =None\n",
    "        self.stump_weights = None\n",
    "        self.errors = None\n",
    "        self.sample_weights = None\n",
    "        \n",
    "    def fit(self, X, y, iters):\n",
    "        n = X.shape[0]\n",
    "\n",
    "        # init numpy arrays\n",
    "        self.sample_weights = np.zeros(shape=(iters, n))\n",
    "        self.stumps = np.zeros(shape=iters, dtype=object)\n",
    "        self.stump_weights = np.zeros(shape=iters)\n",
    "        self.errors = np.zeros(shape=iters)\n",
    "\n",
    "        # initialize weights uniformly\n",
    "        self.sample_weights[0] = np.ones(shape=n) / n\n",
    "\n",
    "        for t in range(iters):\n",
    "            # fit  weak learner\n",
    "            curr_sample_weights = self.sample_weights[t]\n",
    "            stump = DecisionTreeClassifier(max_depth=1, max_leaf_nodes=2)\n",
    "            stump = stump.fit(X, y, sample_weight=curr_sample_weights)\n",
    "\n",
    "            # calculate error and stump weight from weak learner prediction\n",
    "            stump_pred = stump.predict(X)\n",
    "            err = curr_sample_weights[(stump_pred != y)].sum()# / n\n",
    "            stump_weight = np.log((1 - err) / err) / 2\n",
    "\n",
    "            # update sample weights\n",
    "            new_sample_weights = (\n",
    "                curr_sample_weights * np.exp(-stump_weight * y * stump_pred)\n",
    "            )\n",
    "\n",
    "            new_sample_weights /= new_sample_weights.sum()\n",
    "\n",
    "            # If not final iteration, update sample weights for t+1\n",
    "            if t+1 < iters:\n",
    "                self.sample_weights[t+1] = new_sample_weights\n",
    "\n",
    "            # save results of iteration\n",
    "            self.stumps[t] = stump\n",
    "            self.stump_weights[t] = stump_weight\n",
    "            self.errors[t] = err\n",
    "\n",
    "        return self\n",
    "    \n",
    "    \n",
    "    def predict(self, X):\n",
    "        stump_preds = np.array([stump.predict(X) for stump in self.stumps])\n",
    "        return np.sign(np.dot(self.stump_weights, stump_preds))\n",
    "    \n",
    "X=dataset.drop(['Survived'], axis=1).values\n",
    "y=dataset['Survived']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)\n",
    "\n",
    "model = AdaBoost().fit(X_train,y_train,iters=500)\n",
    "y_pred = model.predict(X_test)\n",
    "print(accuracy_score(y_pred,y_test))\n",
    "\n",
    "plt.plot([i for i in range(1,501)],model.errors)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "faeb7023",
   "metadata": {},
   "source": [
    "## Problem 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "fd29884d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50000, 784)\n",
      "(50000, 10)\n",
      "(10000, 784)\n",
      "(10000, 10)\n"
     ]
    }
   ],
   "source": [
    "import pickle, gzip\n",
    "import numpy as np\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.callbacks import EarlyStopping\n",
    "\n",
    "# Load the dataset\n",
    "f = gzip.open('mnist.pkl.gz', 'rb')\n",
    "train_set, valid_set, test_set = pickle.load(f, encoding='latin1')\n",
    "f.close()\n",
    "\n",
    "\n",
    "def to_one_hot(y, num_class=10):\n",
    "    y_vec = np.zeros((y.shape[0],10))\n",
    "    for i in range(len(y)):\n",
    "        y_vec[i][y[i]] = 1\n",
    "    return y_vec\n",
    "\n",
    "\n",
    "X_train = train_set[0]\n",
    "y_train = to_one_hot(train_set[1])\n",
    "print(X_train.shape)\n",
    "print(y_train.shape)\n",
    "X_val = valid_set[0]\n",
    "y_val = to_one_hot(valid_set[1])\n",
    "print(X_val.shape)\n",
    "print(y_val.shape)\n",
    "X_test = test_set[0]\n",
    "y_test = to_one_hot(test_set[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "039af082",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_25\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_60 (Dense)             (None, 500)               392500    \n",
      "_________________________________________________________________\n",
      "dense_61 (Dense)             (None, 500)               250500    \n",
      "_________________________________________________________________\n",
      "dense_62 (Dense)             (None, 10)                5010      \n",
      "=================================================================\n",
      "Total params: 648,010\n",
      "Trainable params: 648,010\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(500, activation='relu', input_shape=(784,)))\n",
    "model.add(Dense(500, activation='relu'))\n",
    "model.add(Dense(10, activation='softmax'))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "36ab8099",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import optimizers\n",
    "model.compile(loss='categorical_crossentropy',optimizer=optimizers.RMSprop(learning_rate=0.0001),metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "bb8a61f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 0.9778 - accuracy: 0.7676 - val_loss: 0.2595 - val_accuracy: 0.9291\n",
      "Epoch 2/50\n",
      "391/391 [==============================] - 2s 4ms/step - loss: 0.2499 - accuracy: 0.9298 - val_loss: 0.1884 - val_accuracy: 0.9487\n",
      "Epoch 3/50\n",
      "391/391 [==============================] - 1s 4ms/step - loss: 0.1892 - accuracy: 0.9466 - val_loss: 0.1576 - val_accuracy: 0.9562\n",
      "Epoch 4/50\n",
      "391/391 [==============================] - 2s 4ms/step - loss: 0.1483 - accuracy: 0.9569 - val_loss: 0.1346 - val_accuracy: 0.9619\n",
      "Epoch 5/50\n",
      "391/391 [==============================] - 2s 4ms/step - loss: 0.1237 - accuracy: 0.9650 - val_loss: 0.1192 - val_accuracy: 0.9654\n",
      "Epoch 6/50\n",
      "391/391 [==============================] - 2s 4ms/step - loss: 0.1015 - accuracy: 0.9718 - val_loss: 0.1122 - val_accuracy: 0.9688\n",
      "Epoch 7/50\n",
      "391/391 [==============================] - 2s 4ms/step - loss: 0.0900 - accuracy: 0.9744 - val_loss: 0.1009 - val_accuracy: 0.9718\n",
      "Epoch 8/50\n",
      "391/391 [==============================] - 2s 4ms/step - loss: 0.0791 - accuracy: 0.9776 - val_loss: 0.0935 - val_accuracy: 0.9732\n",
      "Epoch 9/50\n",
      "391/391 [==============================] - 2s 4ms/step - loss: 0.0662 - accuracy: 0.9807 - val_loss: 0.0916 - val_accuracy: 0.9747\n",
      "Epoch 10/50\n",
      "391/391 [==============================] - 2s 4ms/step - loss: 0.0580 - accuracy: 0.9841 - val_loss: 0.0858 - val_accuracy: 0.9753\n",
      "Epoch 11/50\n",
      "391/391 [==============================] - 2s 4ms/step - loss: 0.0499 - accuracy: 0.9860 - val_loss: 0.0826 - val_accuracy: 0.9774\n",
      "Epoch 12/50\n",
      "391/391 [==============================] - 2s 4ms/step - loss: 0.0427 - accuracy: 0.9885 - val_loss: 0.0817 - val_accuracy: 0.9773\n",
      "Epoch 13/50\n",
      "391/391 [==============================] - 2s 4ms/step - loss: 0.0408 - accuracy: 0.9891 - val_loss: 0.0781 - val_accuracy: 0.9784\n",
      "Epoch 14/50\n",
      "391/391 [==============================] - 2s 4ms/step - loss: 0.0338 - accuracy: 0.9914 - val_loss: 0.0778 - val_accuracy: 0.9788\n",
      "Epoch 15/50\n",
      "391/391 [==============================] - 2s 4ms/step - loss: 0.0306 - accuracy: 0.9917 - val_loss: 0.0753 - val_accuracy: 0.9788\n",
      "Epoch 16/50\n",
      "391/391 [==============================] - 2s 4ms/step - loss: 0.0264 - accuracy: 0.9936 - val_loss: 0.0772 - val_accuracy: 0.9782\n",
      "Epoch 17/50\n",
      "391/391 [==============================] - 2s 4ms/step - loss: 0.0225 - accuracy: 0.9951 - val_loss: 0.0776 - val_accuracy: 0.9785\n",
      "Epoch 18/50\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 0.0209 - accuracy: 0.9953 - val_loss: 0.0738 - val_accuracy: 0.9787\n",
      "Epoch 19/50\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 0.0185 - accuracy: 0.9958 - val_loss: 0.0777 - val_accuracy: 0.9779\n",
      "Epoch 20/50\n",
      "391/391 [==============================] - 2s 4ms/step - loss: 0.0159 - accuracy: 0.9965 - val_loss: 0.0754 - val_accuracy: 0.9783\n",
      "Epoch 21/50\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 0.0147 - accuracy: 0.9968 - val_loss: 0.0751 - val_accuracy: 0.9792\n",
      "Epoch 22/50\n",
      "391/391 [==============================] - 2s 4ms/step - loss: 0.0124 - accuracy: 0.9976 - val_loss: 0.0761 - val_accuracy: 0.9803\n",
      "Epoch 23/50\n",
      "391/391 [==============================] - 2s 4ms/step - loss: 0.0108 - accuracy: 0.9978 - val_loss: 0.0761 - val_accuracy: 0.9800\n"
     ]
    }
   ],
   "source": [
    "es = EarlyStopping(monitor='val_loss', mode='auto', patience=5)\n",
    "history = model.fit(X_train, y_train, batch_size=128, epochs=50, validation_data=(X_val,y_val), callbacks=[es])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "c0a47e21",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "acc = history.history['accuracy']\n",
    "val_acc = history.history['val_accuracy']\n",
    "\n",
    "epochs = range(len(acc))\n",
    "\n",
    "plt.plot(epochs, acc, 'bo', label='Training acc')\n",
    "plt.plot(epochs, val_acc, 'r', label='Validation acc')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "8d33f0f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 0s 911us/step - loss: 0.0678 - accuracy: 0.9807\n",
      "loss = 0.06783760339021683\n",
      "accuracy = 0.9807000160217285\n"
     ]
    }
   ],
   "source": [
    "loss_and_acc = model.evaluate(X_test, y_test)\n",
    "print('loss = ' + str(loss_and_acc[0]))\n",
    "print('accuracy = ' + str(loss_and_acc[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be49881e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
